以分类问题为例,从统计学习的角度来看，可以通过两种手段进行解决。一是构建概率生成模型，通过计算每类的先验概率和类的概率密度，继而使用贝叶斯定理进行分类，
可以证明，贝叶斯分类器具有最小化误分类概率。二是构建判别式模型，根据判断函数取值对任一给定样本进行分类。

## 概率生成模型

在概率生成模型中，其重点是估计针对每类样本的概率密度。对于类概率密度的估计，从是否假定数据服从每一确定的概率分布形式可以将其分为
参数化方法和非参数化方法。

### 1. 参数化方法

参数化方法假定每类数据服从某一特定类型分布，比如正态分布。参数化方法中对类概率密度的估计即是对假设分布形式的参数估计。根据对概率分布中参数
的不同理解，频率学派和贝叶斯学派分别使用不同的手段解决这一问题。

#### 1.1 频率学派的概率分布参数估计

在频率学派看来，尽管概率分布的具体参数未知，但对于总体而言，其为一个确定的值，因此基于极大似然方法可以得到对概率分布的参数估计（当假定训练样本
分布与总体分布相一致时 ）。

#### 1.2 贝叶斯学派的概率分布参数估计

在贝叶斯学派观点中，概率分布参数并非一个确定的值，考虑到当前训练样本的分布形式可能与总体分布不完全一致，贝叶斯学派将类概率分布的参数视作随机变量。
因此，需要计算概率分布参数这一随机变量的后验概率。

### 2. 非参数化方法

不同于参数化方法中预先指定类样本服从某一给定概率分布形式，在非参数化方法不对样本的概率分布作出任何限制。非参数化方法主要包括K近邻、核方法、
贝叶斯网络等。
